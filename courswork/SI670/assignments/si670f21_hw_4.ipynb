{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 4: Linear models, SVMs, Basic data imputation. (Due Thurs. Oct 7, 2021 12:59pm)\n",
    "\n",
    "For this assignment, question 1 is worth 40 points, and question 2 and 3 are worth 20 points each, for a total of 80 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file to Canvas - IMPORTANT: please name your submitted file si670-hw4-youruniqname.ipynb and be sure to put your name at the top of your notebook file.\n",
    "\n",
    "As a reminder, feel free to discuss general approaches to the homework with classmates, but the notebook you submit must be your own work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put your name here: Cameron Milne\n",
    "\n",
    "### Put your uniquename here: ccmilne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (40 points)\n",
    "\n",
    "Please write the answers as well as your derivation process of the following questions. You can use either LaTeX or python code to represent your answer. For example, if you want to present <$x_1^2$>, in the LaTeX format you should write <(dollar sign) x_1^2 (dollar sign)>; in the python code format you should write <\\`x_1\\*\\*2\\`>. See [here](https://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/) for how to represent more mathmatical symbols in LaTeX format.\n",
    "\n",
    "*Note: This question 1 does not require coding.*\n",
    "\n",
    "#### (a) (10 points) \n",
    "\n",
    "If you have data with features $(x_1, x_2)$, what will be the set of the expanded features after you apply the `PolynomialFeatures` transformation with `degree=3` on it? The order of the features does not matter in your answer.\n",
    "\n",
    "#### (b) (10 points) \n",
    "The main metric we have been using to measure the quality of regression models is $R^2$, which is defined as, for n data points, $R^2 = 1 -  \\frac{\\sum_{i=1}^n(\\hat{y}_i - y_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2}$, where $y_i, \\hat{y}_i$ are the label and prediction of data point i, and $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$. We denote $\\frac{1}{n}\\sum_{i=1}^n(\\hat{y}_i - y_i)^2$ as *Unexplained Variation* and $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2$ as *Total Variation*. \n",
    "\n",
    "Given 5 data points with labels (1, 3, 2, -4, 6) and two classifiers A and B, suppose the predictions of A are (1.1, 1.4, 1.3, -2, 2) and the predictions of B are (1.7, 1.3, 0.3, 2, 3). Please calculate and report the *Unexplained Variation*, *Total Variation*, and *$R^2$* for classifiers A and B respectively. \n",
    "\n",
    "#### (c) (20 points) \n",
    "You are given 3 data points with two features $x_1$ and $x_2$ and one label $Y$ as follows,\n",
    "\n",
    "|    X1\t| X2 \t| Y \t|\n",
    "|----\t|----\t|----\t|\n",
    "|   1\t|   1 \t| 1.05 \t|\n",
    "|   0.7 |  3 \t| 0.81 \t|\n",
    "|   2   |  0.5 \t| 2.045 |\n",
    "\n",
    "Suppose you have a linear regression model: $y = w_1 x_1 + w_2 x_2$, please calculate and report the least squares error, the L1 regularization, and the L2 regularization terms for each of the following linear models:\n",
    "\n",
    "(i) $w_1 = 1, w_2 = 0$\n",
    "\n",
    "(ii) $w_1 = 1, w_2 = 0.02$\n",
    "\n",
    "If you set the regularization coefficient $C=1$, which of the above two weights is preferred by the Lasso and which is preferred by Ridge regression? Could you use this example to explain why Lasso prefers sparse models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1(a)\n",
    "\n",
    "$ 1 + x_1 + x_2 + x_1x_2 + x_1x_2^2 + x_1x_2^3 + x_1^2x_2 + x_1^2x_2^2 + x_1^3 + x_2^3 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1(b)\n",
    "\n",
    "$ Sum of Labels = 1.6 = (1 + 3 + 2 + -4 + 6) / 5 $\n",
    "\n",
    "$ Total Variation = 10.66 = ((1-1.6)^2 + (3-1.6)^2 + (2-1.6)^2 + ((-4)-1.6)^2 + (6-1.6)^2) / 5$\n",
    "\n",
    "$ Unexplained A = 4.612 = ((1.1-1)^2 + (1.4-3)^2 + (1.3-2)^2 + (-2-(-4))^2 + (3-6)^2) / 5 $\n",
    "\n",
    "$ Unexplained B = 10.254 = ((1.7-1)^2 + (1.3-3)^2 + (0.3-2)^2 + (2-(-4)^2 + (3-6)^2) / 5 $\n",
    "\n",
    "$ R^2 for Classifier A = 0.56735 = 1 - (4.612/10.66) $\n",
    "\n",
    "$ R^2 for Classifier B = 0.0326 = 1 - (10.254/10.66)  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Answer 1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers for i: 0.01662500000000002, 1, 1\n",
      "Answers for ii: 0.004625000000000016, 1.02, 1.004\n"
     ]
    }
   ],
   "source": [
    "i_LSE = (1.05-((1*1)+(0*1)))**2 + (0.81-((1*0.7)+(0*3)))**2 + (2.045-((1*2)+(0*0.5)))**2\n",
    "i_L1regularization = 1 + 0 #weight 1 + weight 2\n",
    "i_L2regularization = 1\n",
    "\n",
    "print(\"Answers for i: {}, {}, {}\".format(i_LSE, i_L1regularization, i_L2regularization))\n",
    "\n",
    "ii_LSE = (1.05-((1*1)+(0.02*1)))**2 + (0.81-((1*0.7)+(0.02*3)))**2 + (2.045-((1*2)+(0.02*0.5)))**2\n",
    "ii_L1regularization = 1 + 0.02\n",
    "ii_L2regularization = 1.004\n",
    "\n",
    "print(\"Answers for ii: {}, {}, {}\".format(ii_LSE, ii_L1regularization, ii_L2regularization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first estimator, the *Lasso* regression would be best; the *Ridge* regression would be better for the second estimator. \n",
    "\n",
    "The Lasso regression shrinks the less important feature's coefficient to zero, and the second weight in the first estimator is zero already making this the appropriate regularization method. As for the second estimator, the second weight is 0.02, and because the Ridge regularization method captures small weights (in this case the smallest non-zero weight), it's the appropriate method. \n",
    "\n",
    "This example demonstrates why Lasso prefers sparse models -- models where only a small fraction of the parameters are non-zero. Between the weights of 0 and 0.02, the Lasso model will prefer zero as it penalizes small values around zero, or in other words, values that are not the sum of absolute values -- what coefficients are penalized for being further from. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (20 points)\n",
    "\n",
    "First use `MinMaxScaler` to scale the breast cancer data and then use `GridSearchCV` to search the `kernel`, `C`, and `gamma` parameters for `SVC`. Be careful about the data leakage issues. Please return the best hyper-parameters on cross-validation and the test score associated with the these hyper-parameters.\n",
    "\n",
    "Please search the `kernel` from ('linear', 'rbf'), `C` from (0.1, 1, 10, 100), `gamma` from (0.1, 1, 10, 100). And please apply `random_state=0` in both `train_test_split`.\n",
    "\n",
    "*This function should a return a tuple with four numbers, i.e. `(best_kernel, best_C, best_gamma, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rbf', 1, 1, 0.9812311901504789)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    #Load Cancer\n",
    "    cancer = load_breast_cancer(as_frame=True)\n",
    "    d = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "    d['target'] = pd.Series(data=cancer.target, index=d.index)\n",
    "    \n",
    "    #Scale & Split Data\n",
    "    X = d[d.columns.drop('target')]\n",
    "    y = d['target']\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)\n",
    "    \n",
    "    #SVC and GridSearchCV\n",
    "    parameters = {'kernel': ('linear', 'rbf'), 'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]}\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #Best Score function\n",
    "    #print(clf.best_score_) #returns the same model as below\n",
    "    \n",
    "    #Find best model\n",
    "    param_c = clf.cv_results_['param_C']\n",
    "    param_gamma = clf.cv_results_['param_gamma']\n",
    "    param_kernel = clf.cv_results_['param_kernel']\n",
    "    mean_test_score = clf.cv_results_['mean_test_score']\n",
    "    \n",
    "    zipped = list(zip(param_kernel, param_c, param_gamma, mean_test_score))\n",
    "    \n",
    "    best_kernel = None\n",
    "    best_C = None\n",
    "    best_gamma = None\n",
    "    test_score = 0\n",
    "    \n",
    "    for model in zipped:\n",
    "        if model[3] > test_score:\n",
    "            best_kernel = model[0]\n",
    "            best_C = model[1]\n",
    "            best_gamma = model[2]\n",
    "            test_score = model[3]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return best_kernel, best_C, best_gamma, test_score\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3 (20 points)\n",
    "\n",
    "Suppose you have a dataset with some missing values and you know the values are not missing at random and the probability of missing is related to the values themselves. For example, people with higher\n",
    "earnings may be less likely to reveal them. \n",
    "\n",
    "#### (a) (3 points) In this case, what would happen when imputing the missing values with the mean strategy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3(a)\n",
    "\n",
    "Knowing the values are not missing at random but are due to a pattern not readily apparent in the data complicates the question of Imputation. In the example of missing income values, imputing a mean value to replace what we expect are probably higher income values skews the data. It creates an incorrect assessment of reality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance based on the full data: 0.923\n"
     ]
    }
   ],
   "source": [
    "# Please run this cell first before doing question 3(b)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "d = {}\n",
    "for i in range(len(cancer.feature_names)):\n",
    "    d[cancer.feature_names[i]] = cancer.data[:, i]\n",
    "d['target'] = cancer.target\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "X = df[['mean concave points', 'worst concave points']]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), random_state=0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('The performance based on the full data: {:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "X_train_missing = X_train.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 1])[0], 1] = np.nan\n",
    "\n",
    "n_samples = X_test.shape[0]\n",
    "X_test_missing = X_test.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 1])[0], 1] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) (7 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three_b():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # YOUR CODE HERE.\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X_train_imputed = imp.fit_transform(X_train_missing)  \n",
    "    X_test_imputed = imp.transform(X_test_missing)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_imputed, y_train)\n",
    "    test_score = lr.score(X_test_imputed, y_test)\n",
    "    \n",
    "    return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "answer_three_b()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) (5 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'` and `add_indicator=True`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three_c():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # YOUR CODE HERE.\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "    X_train_imputed = imp.fit_transform(X_train_missing)  \n",
    "    X_test_imputed = imp.transform(X_test_missing)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_imputed, y_train)\n",
    "    test_score = lr.score(X_test_imputed, y_test)\n",
    "\n",
    "    return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "answer_three_c()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) (5 points) \n",
    "\n",
    "Why is adding the indicator helpful when the missing values are \"missing not at random\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"add_indicator\" tells the function to omit columns that don't have missing values before fit/train time. If there are missing values in the column, they appear as \"1\"s in the imputed columns of the array that's generated after the fit_transforming the values. This is really helpful because it tells the model where the missing values are which is different from a simple imputer that has an add_indicator of False, which forces the model to assume the missing values are random, decreasing the accuracy score. In other words, a model that makes use of the add_indicator can assume patterns within the data (patterns related to columns) and de-value those features when calculating the accuracy of the model. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f19_lab_2_ans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
